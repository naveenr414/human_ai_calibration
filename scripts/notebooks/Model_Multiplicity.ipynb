{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expertise.multical import assess_callibration_train_test\n",
    "from expertise.utils import generate_side_information_data\n",
    "from expertise.reconcile import compute_train_patches, evaluate_test_patches, evaluate_test_patches_with_human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_N = 1000\n",
    "test_N = 100\n",
    "x_d = 1\n",
    "side_d = 1\n",
    "true_predictor_weights = np.array([1,-1,0])\n",
    "human_predictor_weights = np.array([0,-1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, human_train, y_train, X_test, human_test, y_test = generate_side_information_data(train_N,test_N,x_d,side_d,true_predictor_weights=true_predictor_weights,human_predictor_weights=human_predictor_weights)\n",
    "f_hat = LinearRegression().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_divisions = 10\n",
    "T = 20\n",
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0267237213623705e-32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_augmented = np.concatenate([X_train.T, human_train.reshape(-1,1).T]).T\n",
    "X_test_augmented = np.concatenate([X_test.T, human_test.reshape(-1,1).T]).T\n",
    "f_hat_augmented = LinearRegression().fit(X_train_augmented, y_train)\n",
    "acc_test_augmented = mean_squared_error(f_hat_augmented.predict(X_test_augmented),y_test)\n",
    "acc_test_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16118657674590584"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = f_hat.predict(X_train)\n",
    "cluster_edges = np.linspace(min(predictions), max(predictions), 3)\n",
    "clusters_train = np.digitize(predictions, cluster_edges) - 1 \n",
    "clusters_train = np.clip(clusters_train, 0, 2)\n",
    "predictions = f_hat.predict(X_test)\n",
    "clusteres_test = np.digitize(predictions, cluster_edges) - 1 \n",
    "clusteres_test = np.clip(clusteres_test, 0, 2)\n",
    "train_df = pd.DataFrame(np.array([clusters_train,human_train,y_train]).T,columns=[\"cluster\",\"human\",\"true_y\"])\n",
    "test_df = pd.DataFrame(np.array([clusters_test,human_test,y_test]).T,columns=[\"cluster\",\"human\",\"true_y\"])\n",
    "assess_callibration_train_test(train_df,test_df,\"human\",\"cluster\",\"true_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02612622726726751"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_divisions = [(-10,10)]\n",
    "human_model = LinearRegression().fit(X_train,human_train)\n",
    "human_predictions = human_model.predict(X_train)\n",
    "patches = compute_train_patches(X_train,human_predictions,y_train,f_hat,epsilon,T,y_divisions)\n",
    "evaluate_test_patches(X_train,X_test,human_test,y_test,f_hat,patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00773563661735573"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_divisions = np.linspace(np.min(y_train),np.max(y_train),num_divisions)\n",
    "y_divisions = [(y_divisions[i],y_divisions[i+1]-0.001) for i in range(len(y_divisions)-1)]\n",
    "patches = compute_train_patches(X_train,human_train,y_train,f_hat,epsilon,T,y_divisions)\n",
    "evaluate_test_patches_with_human(X_train,human_train,X_test,human_test,y_test,f_hat,patches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
